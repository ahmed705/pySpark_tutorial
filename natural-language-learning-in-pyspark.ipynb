{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Introduction \n\n- First we build a baseline model using basic Spark API. \n- Secon we fine tune the model using state of art technique using Spark NLP. "},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pyspark","execution_count":1,"outputs":[{"output_type":"stream","text":"Collecting pyspark\n  Downloading pyspark-3.0.0.tar.gz (204.7 MB)\n\u001b[K     |████████████████████████████████| 204.7 MB 17 kB/s s eta 0:00:01\n\u001b[?25hCollecting py4j==0.10.9\n  Downloading py4j-0.10.9-py2.py3-none-any.whl (198 kB)\n\u001b[K     |████████████████████████████████| 198 kB 42.9 MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: pyspark\n  Building wheel for pyspark (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pyspark: filename=pyspark-3.0.0-py2.py3-none-any.whl size=205044182 sha256=152b4fbb687bdbc2080572683e7292efbb1c87669adcc2fb5c6708376a0aaa5f\n  Stored in directory: /root/.cache/pip/wheels/4e/c5/36/aef1bb711963a619063119cc032176106827a129c0be20e301\nSuccessfully built pyspark\nInstalling collected packages: py4j, pyspark\nSuccessfully installed py4j-0.10.9 pyspark-3.0.0\n\u001b[33mWARNING: You are using pip version 20.2.1; however, version 20.2.2 is available.\nYou should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\n","name":"stdout"}]},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"from pyspark.sql import SparkSession\nspark = SparkSession.builder.appName('classification').getOrCreate()","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from pyspark.sql.functions import lower, col, udf, lit, regexp_replace\nfrom pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\nfrom pyspark.sql.types import IntegerType, StringType, StructType, StructField\n\nfrom pyspark.ml.classification import RandomForestClassifier, NaiveBayes, LinearSVC\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\nfrom pyspark.ml.pipeline import Pipeline\n\nfrom pyspark.ml.tuning import CrossValidator, ParamGridBuilder","execution_count":33,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"schema = StructType([StructField('id', IntegerType(), True), \n                      StructField('keyword', StringType(), True), \n                      StructField('location', StringType(), True), \n                      StructField('text', StringType(), True),\n                      StructField('target', IntegerType(), True)\n                     ])\n\ndf1 = spark.read.csv('/kaggle/input/nlp-getting-started/train.csv', header=True, schema=schema)\ndf1 = df1.where(~df1['id'].isNull()).select('target', 'text')\n\ndf2 = spark.read.csv('/kaggle/input/nlp-getting-started/test.csv', header=True, schema=schema)\ndf2 = df2.where(~df2['id'].isNull()).select('id', 'text')\n\nprint('Train data head')\ndf1.show(3)\n\nprint('Test data head')\ndf2.show(3)\n\nprint('Train data size:\\t', df1.count(), \n      '\\nTrain data size:\\t', df2.count())","execution_count":51,"outputs":[{"output_type":"stream","text":"Train data head\n+------+--------------------+\n|target|                text|\n+------+--------------------+\n|     1|Our Deeds are the...|\n|     1|Forest fire near ...|\n|     1|All residents ask...|\n+------+--------------------+\nonly showing top 3 rows\n\nTest data head\n+---+--------------------+\n| id|                text|\n+---+--------------------+\n|  0|Just happened a t...|\n|  2|Heard about #eart...|\n|  3|there is a forest...|\n+---+--------------------+\nonly showing top 3 rows\n\nTrain data size:\t 7613 \nTrain data size:\t 3263\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Train and test data schema')\ndf1.printSchema(), df2.printSchema()\n\ndf1.groupby('target').count().show()","execution_count":52,"outputs":[{"output_type":"stream","text":"Train and test data schema\nroot\n |-- target: integer (nullable = true)\n |-- text: string (nullable = true)\n\nroot\n |-- id: integer (nullable = true)\n |-- text: string (nullable = true)\n\n+------+-----+\n|target|count|\n+------+-----+\n|  null|  437|\n|     1| 3081|\n|     0| 4095|\n+------+-----+\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1.where(~df1['target'].isNull())\ndf1.count()\ndf1.show(3)","execution_count":53,"outputs":[{"output_type":"stream","text":"+------+--------------------+\n|target|                text|\n+------+--------------------+\n|     1|Our Deeds are the...|\n|     1|Forest fire near ...|\n|     1|All residents ask...|\n+------+--------------------+\nonly showing top 3 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Preprocessing "},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(column):\n    \n    # Lowering the capital letters \n    column = lower(column)\n    \n    # Replacing user name \n    column = regexp_replace(column, r'@[^\\s]+', 'USER')\n    \n    # Replacing url \n    column = regexp_replace(column, r'https?://\\S+|www\\.\\S+', 'URL')\n    \n    # Replacing ayyyyy -> ayy \n    column = regexp_replace(column, r'(.)\\1\\1+', r'\\1\\1')\n    \n    # Replacing other than alphabets \n    column = regexp_replace(column, r'[^a-zA-Z\\d\\s]', '')\n    column = regexp_replace(column, r'\\d+', 'NUM')\n    \n    return column","execution_count":54,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df1 = df1.withColumn('text', preprocess(col('text')))\ndf2 = df2.withColumn('text', preprocess(col('text')))\n\ndf1.show(3)\ndf2.show(3)","execution_count":55,"outputs":[{"output_type":"stream","text":"+------+--------------------+\n|target|                text|\n+------+--------------------+\n|     1|our deeds are the...|\n|     1|forest fire near ...|\n|     1|all residents ask...|\n+------+--------------------+\nonly showing top 3 rows\n\n+---+--------------------+\n| id|                text|\n+---+--------------------+\n|  0|just happened a t...|\n|  2|heard about earth...|\n|  3|there is a forest...|\n+---+--------------------+\nonly showing top 3 rows\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Model building "},{"metadata":{"trusted":true},"cell_type":"code","source":"train, test = df1.randomSplit([0.7, 0.3])","execution_count":56,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Total number of stopwords: \\t', len(StopWordsRemover().getStopWords()))\nprint('Example stopwords: \\t\\t', StopWordsRemover().getStopWords()[:5])","execution_count":57,"outputs":[{"output_type":"stream","text":"Total number of stopwords: \t 181\nExample stopwords: \t\t ['i', 'me', 'my', 'myself', 'we']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"evaluator = MulticlassClassificationEvaluator(labelCol='target', metricName='accuracy')","execution_count":58,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tokenizer = Tokenizer(inputCol='text', outputCol='text_token')\nremover = StopWordsRemover(inputCol='text_token', outputCol='text_trim')\n\nhashingTF = HashingTF(inputCol='text_trim', outputCol='raw_feat', numFeatures=10000)\nidf = IDF(inputCol='raw_feat', outputCol='features')","execution_count":59,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"rf = RandomForestClassifier(labelCol='target', \n                            maxDepth=16, \n                            numTrees=100)\n\nnb = NaiveBayes(labelCol='target', smoothing=200)\nsvc = LinearSVC(labelCol='target', regParam=1, maxIter=20)","execution_count":60,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"pipeline_rf = Pipeline(stages=[tokenizer, remover, hashingTF, idf, rf])\npipeline_nb = Pipeline(stages=[tokenizer, remover, hashingTF, idf, nb])\npipeline_svc = Pipeline(stages=[tokenizer, remover, hashingTF, idf, svc])","execution_count":61,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = {'Random forest': pipeline_rf, \n               'Naive Bayes' : pipeline_nb, \n               'SVM classifier' : pipeline_svc}\n\nfor name in model_names:\n    model = model_names[name].fit(train)\n    pred = model.transform(test)\n    score = evaluator.evaluate(pred)\n    print(name.ljust(30), score)","execution_count":62,"outputs":[{"output_type":"stream","text":"Random forest                  0.6693434104865376\nNaive Bayes                    0.7808219178082192\nSVM classifier                 0.7529522909777988\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"paramGrid = ParamGridBuilder() \\\n    .addGrid(hashingTF.numFeatures, [10000, 100000]) \\\n    .addGrid(nb.smoothing, [100, 200, 300]) \\\n    .build()","execution_count":63,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_names = {'Naive Bayes' : pipeline_nb}\n\nfor name in model_names:\n    crossval = CrossValidator(estimator=model_names[name],\n                              estimatorParamMaps=paramGrid,\n                              evaluator=evaluator,\n                              numFolds=5)\n    \n    model = crossval.fit(df1)\n    pred = model.transform(df1)\n    score = evaluator.evaluate(pred)\n    print(name.ljust(30), score)","execution_count":64,"outputs":[{"output_type":"stream","text":"Naive Bayes                    0.8663600891861761\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Null text ? "},{"metadata":{"trusted":true},"cell_type":"code","source":"df1.where(df1['text'].isNull()).show()\ndf2.where(df2['text'].isNull()).show()","execution_count":65,"outputs":[{"output_type":"stream","text":"+------+----+\n|target|text|\n+------+----+\n+------+----+\n\n+-----+----+\n|   id|text|\n+-----+----+\n| 7524|null|\n|10103|null|\n+-----+----+\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_null = df2.where(df2['text'].isNull()).\\\n            withColumn('target', lit(0)).select('id', 'target')\npred_null.show()\n\ndf2 = df2.dropna()","execution_count":66,"outputs":[{"output_type":"stream","text":"+-----+------+\n|   id|target|\n+-----+------+\n| 7524|     0|\n|10103|     0|\n+-----+------+\n\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Prediction "},{"metadata":{"trusted":true},"cell_type":"code","source":"pred_test = model.transform(df2).select('id', 'prediction')\n\npredictions = pred_test.\\\n                withColumn('target', pred_test['prediction'].\\\n                cast('integer')).drop('prediction')\n\npredictions.show(4)","execution_count":67,"outputs":[{"output_type":"stream","text":"+---+------+\n| id|target|\n+---+------+\n|  0|     1|\n|  2|     0|\n|  3|     1|\n|  9|     1|\n| 11|     1|\n+---+------+\nonly showing top 5 rows\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions = predictions.union(pred_null)\npredictions.count()","execution_count":74,"outputs":[{"output_type":"execute_result","execution_count":74,"data":{"text/plain":"3265"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predictions.toPandas().to_csv('submission.csv', index=False)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\npd.read_csv('submission.csv').sample(5)","execution_count":73,"outputs":[{"output_type":"execute_result","execution_count":73,"data":{"text/plain":"        id  target\n1717  5788       1\n2391  7997       0\n395   1281       0\n2739  9127       1\n1840  6214       1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1717</th>\n      <td>5788</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2391</th>\n      <td>7997</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>395</th>\n      <td>1281</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2739</th>\n      <td>9127</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1840</th>\n      <td>6214</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"# Future direction \n\n- Emoji and Emoticons \n- Lementation "},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}