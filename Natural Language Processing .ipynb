{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# There is a Kaggle course on NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('nlp').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import lower, col, udf, regexp_replace\n",
    "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
    "from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier, NaiveBayes, LinearSVC\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+--------------------+------+\n",
      "| id|keyword|location|                text|target|\n",
      "+---+-------+--------+--------------------+------+\n",
      "|  1|   null|    null|Our Deeds are the...|     1|\n",
      "|  4|   null|    null|Forest fire near ...|     1|\n",
      "|  5|   null|    null|All residents ask...|     1|\n",
      "|  6|   null|    null|13,000 people rec...|     1|\n",
      "+---+-------+--------+--------------------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('disaster_tweet_train.csv', header=True, inferSchema=True)\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- keyword: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- text: string (nullable = true)\n",
      " |-- target: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8387, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4771, 5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna()\n",
    "df.count(), len(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|target|count|\n",
      "+------+-----+\n",
      "|     1| 2062|\n",
      "|     0| 2709|\n",
      "+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupby('target').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                text|target|\n",
      "+--------------------+------+\n",
      "|@bbcmtd Wholesale...|     1|\n",
      "|We always try to ...|     0|\n",
      "|#AFRICANBAZE: Bre...|     1|\n",
      "|Crying out for mo...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.select('text', 'target')\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(column):\n",
    "    \n",
    "    # Lowering the capital letters \n",
    "    column = lower(column)\n",
    "    \n",
    "    # Replacing user name \n",
    "    column = regexp_replace(column, r'@[^\\s]+', 'USER')\n",
    "    \n",
    "    # Replacing url \n",
    "    column = regexp_replace(column, r'https?://\\S+|www\\.\\S+', 'URL')\n",
    "    \n",
    "    # Replacing ayyyyy -> ayy \n",
    "    column = regexp_replace(column, r'(.)\\1\\1+', r'\\1\\1')\n",
    "    \n",
    "    # Replacing other than alphabets \n",
    "    column = regexp_replace(column, r'[^a-zA-Z\\d\\s]', '')\n",
    "    column = regexp_replace(column, r'\\d+', 'NUM')\n",
    "    \n",
    "    return column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+\n",
      "|                text|target|\n",
      "+--------------------+------+\n",
      "|USER wholesale ma...|     1|\n",
      "|we always try to ...|     0|\n",
      "|africanbaze break...|     1|\n",
      "|crying out for mo...|     0|\n",
      "|on plus side look...|     0|\n",
      "+--------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.withColumn('text', preprocess(col('text')))\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization, removing stop words and Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol='text', outputCol='text_token')\n",
    "remover = StopWordsRemover(inputCol='text_token', outputCol='text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|                text|\n",
      "+------+--------------------+\n",
      "|     1|[user, wholesale,...|\n",
      "|     0|[always, try, bri...|\n",
      "|     1|[africanbaze, bre...|\n",
      "|     0|[crying, set, abl...|\n",
      "|     0|[plus, side, look...|\n",
      "+------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = tokenizer.transform(df).drop('text')\n",
    "df = remover.transform(df).drop('text_token')\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of stopwords: \t 181\n",
      "Example stopwords: \t\t ['i', 'me', 'my', 'myself', 'we']\n"
     ]
    }
   ],
   "source": [
    "print('Total number of stopwords: \\t', len(StopWordsRemover().getStopWords()))\n",
    "print('Example stopwords: \\t\\t', StopWordsRemover().getStopWords()[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashingTF = HashingTF(inputCol='text', outputCol='raw_feat', numFeatures=1000)\n",
    "idf = IDF(inputCol='raw_feat', outputCol='features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|target|            features|\n",
      "+------+--------------------+\n",
      "|     1|(10000,[2025,3862...|\n",
      "|     0|(10000,[426,3057,...|\n",
      "|     1|(10000,[1527,3714...|\n",
      "|     0|(10000,[5342,7657...|\n",
      "+------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = hashingTF.transform(df)\n",
    "idf_model = idf.fit(df)\n",
    "df = idf_model.transform(df).select('target', 'features')\n",
    "df.show(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model building "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = MulticlassClassificationEvaluator(labelCol='target', metricName='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6798365122615804"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(labelCol='target', \n",
    "                            maxDepth=16, \n",
    "                            numTrees=100)\n",
    "\n",
    "model = rf.fit(train)\n",
    "pred = model.transform(test)\n",
    "evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.771117166212534"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = NaiveBayes(labelCol='target', smoothing=200)\n",
    "\n",
    "model = nb.fit(train)\n",
    "pred = model.transform(test)\n",
    "evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7411444141689373"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc = LinearSVC(labelCol='target', regParam=1, maxIter=20)\n",
    "\n",
    "model = svc.fit(train)\n",
    "pred = model.transform(test)\n",
    "evaluator.evaluate(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future direction \n",
    "\n",
    "- Pipeline \n",
    "- Emoji and emoticons \n",
    "- Lementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
